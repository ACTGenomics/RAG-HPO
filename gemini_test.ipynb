{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "815a7bb0-3e54-4fe2-9b33-38ce32064dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing GeminiNativeClient...\n",
      "========================================\n",
      "Raw Response:\n",
      "<think>\n",
      "**Understanding and Calculating a Percentage**\n",
      "\n",
      "Alright, let's break this down. My goal is to determine 15% of 280. As an expert, I know that percentage inherently means \"out of one hundred.\" So, 15% is simply the same as 15/100.\n",
      "\n",
      "To make the calculation easier, I'll convert that percentage into its decimal equivalent. We can do this by dividing the percentage by 100: 15% becomes 15/100, which equals 0.15.\n",
      "\n",
      "Now, the \"of\" in \"15% of 280\" translates to multiplication in this mathematical context.  Therefore, I need to calculate 0.15 multiplied by 280. I'll set it up this way: 0.15 * 280.\n",
      "\n",
      "Let's do the math. When I multiply 280 by 0.15, I get 42.00, which simplifies to 42.\n",
      "\n",
      "And there you have it! 15% of 280 equals 42.\n",
      "\n",
      "As an additional point for deeper understanding, consider this: I can also think of 15% as 10% plus 5%. Knowing this, I could calculate 10% of 280 (which is 28) and then 5% of 280 (which is half of 28, or 14). Adding those two results, 28 + 14, yields the same answer: 42.\n",
      "</think>\n",
      "\n",
      "Okay, let's calculate 15% of 280.\n",
      "\n",
      "Here are the steps:\n",
      "\n",
      "1.  **Understand what \"percent\" means:** The word \"percent\" means \"out of one hundred\". So, 15% is the same as 15 out of 100, which can be written as a fraction $\\frac{15}{100}$.\n",
      "\n",
      "2.  **Convert the percentage to a decimal:** To make calculations easier, we can convert the percentage into a decimal. We do this by dividing the percentage number by 100.\n",
      "    $15\\% = \\frac{15}{100} = 0.15$\n",
      "\n",
      "3.  **Understand \"of\" means multiply:** In mathematics, when you see \"of\" in a problem like this, it means you need to multiply. So, \"15% of 280\" means $0.15 \\times 280$.\n",
      "\n",
      "4.  **Perform the multiplication:**\n",
      "    $0.15 \\times 280$\n",
      "\n",
      "    You can multiply this as:\n",
      "    $0.15 \\times 280 = (0.10 \\times 280) + (0.05 \\times 280)$\n",
      "    *   $0.10 \\times 280 = 28$ (This is like finding 10% of 280, which is just moving the decimal point one place to the left).\n",
      "    *   $0.05 \\times 280 = 14$ (This is like finding 5% of 280, which is half of 10%, so half of 28).\n",
      "\n",
      "    Now, add the two parts together:\n",
      "    $28 + 14 = 42$\n",
      "\n",
      "    Alternatively, you can do the multiplication directly:\n",
      "    ```\n",
      "      280\n",
      "    x 0.15\n",
      "    ------\n",
      "     1400  (280 * 5)\n",
      "    2800   (280 * 1, shifted one place left)\n",
      "    ------\n",
      "    4200\n",
      "    ```\n",
      "    Since there are two decimal places in 0.15, we place the decimal point two places from the right in our answer: 42.00.\n",
      "\n",
      "**Answer:**\n",
      "15% of 280 is **42**.\n",
      "\n",
      "Has Thinking: True\n",
      "Thinking Process:\n",
      "**Understanding and Calculating a Percentage**\n",
      "\n",
      "Alright, let's break this down. My goal is to determine 15% of 280. As an expert, I know that percentage inherently means \"out of one hundred.\" So, 15% is simply the same as 15/100.\n",
      "\n",
      "To make the calculation easier, I'll convert that percentage into its decimal equivalent. We can do this by dividing the percentage by 100: 15% becomes 15/100, which equals 0.15.\n",
      "\n",
      "Now, the \"of\" in \"15% of 280\" translates to multiplication in this mathematical context.  Therefore, I need to calculate 0.15 multiplied by 280. I'll set it up this way: 0.15 * 280.\n",
      "\n",
      "Let's do the math. When I multiply 280 by 0.15, I get 42.00, which simplifies to 42.\n",
      "\n",
      "And there you have it! 15% of 280 equals 42.\n",
      "\n",
      "As an additional point for deeper understanding, consider this: I can also think of 15% as 10% plus 5%. Knowing this, I could calculate 10% of 280 (which is 28) and then 5% of 280 (which is half of 28, or 14). Adding those two results, 28 + 14, yields the same answer: 42.\n",
      "\n",
      "Final Content:\n",
      "Okay, let's calculate 15% of 280.\n",
      "\n",
      "Here are the steps:\n",
      "\n",
      "1.  **Understand what \"percent\" means:** The word \"percent\" means \"out of one hundred\". So, 15% is the same as 15 out of 100, which can be written as a fraction $\\frac{15}{100}$.\n",
      "\n",
      "2.  **Convert the percentage to a decimal:** To make calculations easier, we can convert the percentage into a decimal. We do this by dividing the percentage number by 100.\n",
      "    $15\\% = \\frac{15}{100} = 0.15$\n",
      "\n",
      "3.  **Understand \"of\" means multiply:** In mathematics, when you see \"of\" in a problem like this, it means you need to multiply. So, \"15% of 280\" means $0.15 \\times 280$.\n",
      "\n",
      "4.  **Perform the multiplication:**\n",
      "    $0.15 \\times 280$\n",
      "\n",
      "    You can multiply this as:\n",
      "    $0.15 \\times 280 = (0.10 \\times 280) + (0.05 \\times 280)$\n",
      "    *   $0.10 \\times 280 = 28$ (This is like finding 10% of 280, which is just moving the decimal point one place to the left).\n",
      "    *   $0.05 \\times 280 = 14$ (This is like finding 5% of 280, which is half of 10%, so half of 28).\n",
      "\n",
      "    Now, add the two parts together:\n",
      "    $28 + 14 = 42$\n",
      "\n",
      "    Alternatively, you can do the multiplication directly:\n",
      "    ```\n",
      "      280\n",
      "    x 0.15\n",
      "    ------\n",
      "     1400  (280 * 5)\n",
      "    2800   (280 * 1, shifted one place left)\n",
      "    ------\n",
      "    4200\n",
      "    ```\n",
      "    Since there are two decimal places in 0.15, we place the decimal point two places from the right in our answer: 42.00.\n",
      "\n",
      "**Answer:**\n",
      "15% of 280 is **42**.\n",
      "\n",
      "‚úÖ Test completed successfully!\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Simple test script for GeminiNativeClient\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "from llm_clients import GeminiNativeClient\n",
    "\n",
    "def extract_thinking_from_content(content: str) -> tuple:\n",
    "    \"\"\"Extract thinking process from <think>...</think> tags\"\"\"\n",
    "    if not content:\n",
    "        return \"\", \"\"\n",
    "    \n",
    "    think_pattern = r'<think>(.*?)</think>'\n",
    "    matches = re.findall(think_pattern, content, re.DOTALL)\n",
    "    \n",
    "    if matches:\n",
    "        thinking_process = matches[0].strip()\n",
    "        cleaned_content = re.sub(think_pattern, '', content, flags=re.DOTALL).strip()\n",
    "        return thinking_process, cleaned_content\n",
    "    else:\n",
    "        return \"\", content\n",
    "\n",
    "def test_gemini_client():\n",
    "    \"\"\"Test GeminiNativeClient with thinking mode\"\"\"\n",
    "    \n",
    "    # Initialize client (you need to set your API key)\n",
    "    api_key = \"AIzaSyDcSzeBZQ8lvCkpl2693ogJ4HwFUCZ7MxQ\"\n",
    "    \n",
    "    # Test with thinking enabled\n",
    "    client = GeminiNativeClient(\n",
    "        api_key=api_key,\n",
    "        model_name=\"gemini-2.5-flash-lite\",\n",
    "        temperature=0.2,\n",
    "        think=True,  # Enable thinking mode\n",
    "        max_queries_per_minute=10\n",
    "    )\n",
    "    \n",
    "    print(\"Testing GeminiNativeClient...\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Test query\n",
    "    system_msg = \"You are a helpful assistant that shows reasoning.\"\n",
    "    user_input = \"Calculate 15% of 280 and explain your steps.\"\n",
    "    \n",
    "    try:\n",
    "        response = client.query(user_input, system_msg)\n",
    "        print(f\"Raw Response:\\n{response}\\n\")\n",
    "        \n",
    "        # Test thinking extraction (like FastAPI does)\n",
    "        thinking, content = extract_thinking_from_content(response)\n",
    "        \n",
    "        print(f\"Has Thinking: {bool(thinking)}\")\n",
    "        if thinking:\n",
    "            print(f\"Thinking Process:\\n{thinking}\\n\")\n",
    "        print(f\"Final Content:\\n{content}\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Test completed successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Test failed: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_gemini_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36ac654c-3e6e-463c-a107-b8584183452d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ HPO EXTRACTION E2E TEST\n",
      "============================================================\n",
      "Loading and setting up HPO module...\n",
      "‚úÖ Loaded system prompts from file\n",
      "Initializing LLM client...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: cuda:0\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: pritamdeka/SapBERT-mnli-snli-scinli-scitail-mednli-stsb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings model...\n",
      "Loading vector database...\n",
      "Initializing cache...\n",
      "‚úÖ All components initialized\n",
      "\n",
      "============================================================\n",
      "TESTING INDIVIDUAL STEPS\n",
      "============================================================\n",
      "üìù Step 1: Raw Extraction Test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:google_genai.models:AFC is enabled with max remote calls: 10.\n",
      "INFO:httpx:HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-lite:generateContent \"HTTP/1.1 200 OK\"\n",
      "INFO:google_genai.models:AFC remote call 1 is done.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw response length: 642 chars\n",
      "Raw response preview: Here are the clinical phenotypes extracted from the patient information:\n",
      "\n",
      "1.  **HPO ID:** HP:0001249\n",
      "    **Phenotype:** Intellectual disability\n",
      "2.  **HPO ID:** HP:0001250\n",
      "    **Phenotype:** Seizures\n",
      "3...\n",
      "‚ùå JSON parsing failed\n",
      "‚ùå Individual steps test failed\n"
     ]
    }
   ],
   "source": [
    "# \"\"\"\n",
    "# Corrected E2E test for the actual HPO extraction pipeline\n",
    "# Tests the modified extract_hpo_terms() function directly\n",
    "# \"\"\"\n",
    "# import json\n",
    "# import importlib.util\n",
    "# import time\n",
    "\n",
    "# # Test clinical text\n",
    "# CLINICAL_TEXT = \"\"\"\n",
    "# Patient is a 8-year-old girl with intellectual disability and seizures. \n",
    "# She has microcephaly, hypotonia, and delayed speech development. \n",
    "# Physical exam shows strabismus and hearing impairment. \n",
    "# Lab results indicate elevated liver enzymes and metabolic acidosis.\n",
    "# \"\"\"\n",
    "\n",
    "# def load_and_setup_module():\n",
    "#     \"\"\"Load and set up the HPO module\"\"\"\n",
    "#     print(\"Loading and setting up HPO module...\")\n",
    "    \n",
    "#     # Load the module\n",
    "#     spec = importlib.util.spec_from_file_location(\"hpo_module\", \"deeprare-rag-hpo.py\")\n",
    "#     hpo_module = importlib.util.module_from_spec(spec)\n",
    "#     spec.loader.exec_module(hpo_module)\n",
    "    \n",
    "#     # Load system prompts from file\n",
    "#     try:\n",
    "#         with open(\"deeprare_system_prompts.json\", \"r\", encoding='utf-8') as f:\n",
    "#             prompts = json.load(f)\n",
    "        \n",
    "#         hpo_module.system_message_extract = prompts.get(\"system_message_extract\", \"\")\n",
    "#         hpo_module.system_message_normalize = prompts.get(\"system_message_normalize\", \"\")\n",
    "        \n",
    "#         print(\"‚úÖ Loaded system prompts from file\")\n",
    "#     except FileNotFoundError:\n",
    "#         print(\"‚ùå system_prompts.json not found, using default prompts\")\n",
    "#         return None\n",
    "    \n",
    "#     # Initialize components\n",
    "#     try:\n",
    "#         print(\"Initializing LLM client...\")\n",
    "#         hpo_module.llm_client = hpo_module.check_and_initialize_llm()\n",
    "        \n",
    "#         print(\"Loading embeddings model...\")\n",
    "#         hpo_module.embeddings_model = hpo_module.SentenceTransformer('pritamdeka/SapBERT-mnli-snli-scinli-scitail-mednli-stsb')\n",
    "        \n",
    "#         print(\"Loading vector database...\")\n",
    "#         docs, emb_matrix = hpo_module.load_vector_db()\n",
    "#         hpo_module.embedded_documents = docs\n",
    "#         hpo_module.faiss_index = hpo_module.create_faiss_index(emb_matrix)\n",
    "        \n",
    "#         print(\"Initializing cache...\")\n",
    "#         hpo_module.cache = hpo_module.SimpleCache()\n",
    "        \n",
    "#         print(\"‚úÖ All components initialized\")\n",
    "#         return hpo_module\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Component initialization failed: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def test_individual_steps(hpo_module):\n",
    "#     \"\"\"Test each step individually for debugging\"\"\"\n",
    "#     print(\"\\n\" + \"=\" * 60)\n",
    "#     print(\"TESTING INDIVIDUAL STEPS\")\n",
    "#     print(\"=\" * 60)\n",
    "    \n",
    "#     # Test Step 1: Extraction\n",
    "#     print(\"üìù Step 1: Raw Extraction Test\")\n",
    "#     try:\n",
    "#         response1 = hpo_module.llm_client.query(CLINICAL_TEXT, hpo_module.system_message_extract)\n",
    "#         print(f\"Raw response length: {len(response1)} chars\")\n",
    "#         print(f\"Raw response preview: {response1[:200]}...\")\n",
    "        \n",
    "#         # Test JSON parsing\n",
    "#         parsed1 = hpo_module._safe_json_loads(response1)\n",
    "#         if parsed1:\n",
    "#             print(f\"‚úÖ JSON parsing successful\")\n",
    "#             print(f\"Type: {type(parsed1)}\")\n",
    "#             if isinstance(parsed1, list):\n",
    "#                 print(f\"Found {len(parsed1)} items\")\n",
    "#                 for i, item in enumerate(parsed1[:3]):  # Show first 3\n",
    "#                     if isinstance(item, dict):\n",
    "#                         hpo_id = item.get('HPO') or item.get('hpo_id', 'N/A')\n",
    "#                         phenotype = item.get('Phenotype') or item.get('phenotype', 'N/A')\n",
    "#                         print(f\"  {i+1}. {hpo_id}: {phenotype}\")\n",
    "#         else:\n",
    "#             print(\"‚ùå JSON parsing failed\")\n",
    "#             return False\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Step 1 failed: {e}\")\n",
    "#         return False\n",
    "    \n",
    "#     # Test Step 2: Normalization\n",
    "#     print(f\"\\nüìù Step 2: Raw Normalization Test\")\n",
    "#     test_phenotype = \"seizures\"\n",
    "#     try:\n",
    "#         response2 = hpo_module.llm_client.query(test_phenotype, hpo_module.system_message_normalize)\n",
    "#         print(f\"Input: {test_phenotype}\")\n",
    "#         print(f\"Raw response: {response2}\")\n",
    "        \n",
    "#         # Test JSON parsing\n",
    "#         parsed2 = hpo_module._safe_json_loads(response2)\n",
    "#         if parsed2 and isinstance(parsed2, dict):\n",
    "#             original = parsed2.get('original_term', 'N/A')\n",
    "#             normalized = parsed2.get('hpo_term', 'N/A')\n",
    "#             print(f\"‚úÖ Normalization successful\")\n",
    "#             print(f\"Original: {original}\")\n",
    "#             print(f\"Normalized: {normalized}\")\n",
    "#         else:\n",
    "#             print(\"‚ùå Normalization parsing failed\")\n",
    "#             return False\n",
    "            \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Step 2 failed: {e}\")\n",
    "#         return False\n",
    "    \n",
    "#     return True\n",
    "\n",
    "# def test_full_pipeline(hpo_module):\n",
    "#     \"\"\"Test the complete pipeline\"\"\"\n",
    "#     print(\"\\n\" + \"=\" * 60)\n",
    "#     print(\"TESTING COMPLETE PIPELINE\")\n",
    "#     print(\"=\" * 60)\n",
    "    \n",
    "#     print(f\"Input clinical text:\")\n",
    "#     print(f\"'{CLINICAL_TEXT.strip()}'\")\n",
    "#     print(f\"Length: {len(CLINICAL_TEXT)} characters\")\n",
    "    \n",
    "#     try:\n",
    "#         print(\"\\nRunning extract_hpo_terms()...\")\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         result = hpo_module.extract_hpo_terms(CLINICAL_TEXT)\n",
    "        \n",
    "#         end_time = time.time()\n",
    "#         processing_time = end_time - start_time\n",
    "        \n",
    "#         print(f\"Processing completed in {processing_time:.3f} seconds\")\n",
    "        \n",
    "#         return result, processing_time\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå Pipeline failed: {e}\")\n",
    "#         import traceback\n",
    "#         traceback.print_exc()\n",
    "#         return None, 0\n",
    "\n",
    "# def analyze_results(result, processing_time):\n",
    "#     \"\"\"Analyze the pipeline results\"\"\"\n",
    "#     if not result:\n",
    "#         print(\"‚ùå No results to analyze\")\n",
    "#         return False\n",
    "    \n",
    "#     print(\"\\n\" + \"=\" * 60)\n",
    "#     print(\"RESULTS ANALYSIS\")\n",
    "#     print(\"=\" * 60)\n",
    "    \n",
    "#     # Basic structure\n",
    "#     print(f\"Result type: {type(result)}\")\n",
    "#     print(f\"Keys: {list(result.keys()) if isinstance(result, dict) else 'N/A'}\")\n",
    "    \n",
    "#     # HPO terms analysis\n",
    "#     if 'hpo_terms' in result:\n",
    "#         hpo_terms = result['hpo_terms']\n",
    "#         print(f\"\\nüìä Found {len(hpo_terms)} HPO terms:\")\n",
    "        \n",
    "#         if hpo_terms:\n",
    "#             for i, term in enumerate(hpo_terms, 1):\n",
    "#                 phrase = term.get('phrase', 'N/A')\n",
    "#                 hpo_id = term.get('hpo_id', 'N/A')\n",
    "#                 normalized = term.get('normalized_term', 'N/A')\n",
    "#                 score = term.get('similarity_score', 0)\n",
    "                \n",
    "#                 print(f\"  {i}. {hpo_id} - {phrase}\")\n",
    "#                 print(f\"     Normalized: {normalized}\")\n",
    "#                 print(f\"     Similarity: {score:.3f}\")\n",
    "#         else:\n",
    "#             print(\"  No HPO terms extracted\")\n",
    "    \n",
    "#     # Thinking process\n",
    "#     if 'thinking_process' in result:\n",
    "#         thinking = result['thinking_process']\n",
    "#         print(f\"\\nüß† Thinking process length: {len(thinking)} chars\")\n",
    "#         if thinking:\n",
    "#             lines = thinking.split('\\n')[:10]  # First 10 lines\n",
    "#             print(\"First few lines:\")\n",
    "#             for line in lines:\n",
    "#                 if line.strip():\n",
    "#                     print(f\"  {line[:80]}{'...' if len(line) > 80 else ''}\")\n",
    "    \n",
    "#     # Performance\n",
    "#     print(f\"\\n‚ö° Performance:\")\n",
    "#     print(f\"  Processing time: {processing_time:.3f}s\")\n",
    "#     print(f\"  HPO terms found: {len(result.get('hpo_terms', []))}\")\n",
    "    \n",
    "#     # Format validation\n",
    "#     print(f\"\\n‚úÖ Format validation:\")\n",
    "#     valid = True\n",
    "    \n",
    "#     if not isinstance(result, dict):\n",
    "#         print(\"  ‚ùå Result should be dict\")\n",
    "#         valid = False\n",
    "    \n",
    "#     required_keys = ['hpo_terms', 'thinking_process']\n",
    "#     for key in required_keys:\n",
    "#         if key in result:\n",
    "#             print(f\"  ‚úÖ Has {key}\")\n",
    "#         else:\n",
    "#             print(f\"  ‚ùå Missing {key}\")\n",
    "#             valid = False\n",
    "    \n",
    "#     if 'hpo_terms' in result and isinstance(result['hpo_terms'], list):\n",
    "#         print(f\"  ‚úÖ hpo_terms is list\")\n",
    "#         for i, term in enumerate(result['hpo_terms']):\n",
    "#             if isinstance(term, dict) and 'hpo_id' in term and 'phrase' in term:\n",
    "#                 print(f\"  ‚úÖ Term {i+1} has required fields\")\n",
    "#             else:\n",
    "#                 print(f\"  ‚ùå Term {i+1} missing required fields\")\n",
    "#                 valid = False\n",
    "    \n",
    "#     return valid and len(result.get('hpo_terms', [])) > 0\n",
    "\n",
    "# def main():\n",
    "#     \"\"\"Main test function\"\"\"\n",
    "#     print(\"üß™ HPO EXTRACTION E2E TEST\")\n",
    "#     print(\"=\" * 60)\n",
    "    \n",
    "#     # Setup\n",
    "#     hpo_module = load_and_setup_module()\n",
    "#     if not hpo_module:\n",
    "#         print(\"‚ùå Setup failed\")\n",
    "#         return\n",
    "    \n",
    "#     # Test individual steps first\n",
    "#     if not test_individual_steps(hpo_module):\n",
    "#         print(\"‚ùå Individual steps test failed\")\n",
    "#         return\n",
    "    \n",
    "#     # Test full pipeline\n",
    "#     result, processing_time = test_full_pipeline(hpo_module)\n",
    "#     if not result:\n",
    "#         print(\"‚ùå Full pipeline test failed\")\n",
    "#         return\n",
    "    \n",
    "#     # Analyze results\n",
    "#     success = analyze_results(result, processing_time)\n",
    "    \n",
    "#     # Show full JSON\n",
    "#     print(f\"\\nüìÑ FULL JSON RESULT:\")\n",
    "#     print(\"=\" * 30)\n",
    "#     try:\n",
    "#         print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå JSON serialization failed: {e}\")\n",
    "    \n",
    "#     # Final verdict\n",
    "#     print(\"\\n\" + \"=\" * 60)\n",
    "#     print(\"FINAL VERDICT\")\n",
    "#     print(\"=\" * 60)\n",
    "    \n",
    "#     if success:\n",
    "#         print(\"üéâ TEST PASSED!\")\n",
    "#         hpo_count = len(result.get('hpo_terms', []))\n",
    "#         print(f\"‚úÖ Successfully extracted {hpo_count} HPO terms\")\n",
    "#         print(f\"‚úÖ Processing time: {processing_time:.3f}s\")\n",
    "#         print(\"‚úÖ All format validations passed\")\n",
    "        \n",
    "#         if hpo_count > 0:\n",
    "#             print(\"\\nExtracted HPO terms:\")\n",
    "#             for i, term in enumerate(result['hpo_terms'], 1):\n",
    "#                 hpo_id = term.get('hpo_id', 'N/A')\n",
    "#                 phrase = term.get('phrase', 'N/A')\n",
    "#                 score = term.get('similarity_score', 0)\n",
    "#                 print(f\"  {i}. {hpo_id}: {phrase} (sim: {score:.3f})\")\n",
    "#     else:\n",
    "#         print(\"‚ùå TEST FAILED!\")\n",
    "#         print(\"Check the error messages above for details\")\n",
    "    \n",
    "#     print(\"=\" * 60)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24983079-1410-4bfb-a7b0-4213a2c048fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
